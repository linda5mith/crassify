Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job                     count
--------------------  -------
all                         1
crassify                    1
decenttree                  1
dendogram                   1
run_diamond_blastp          1
translate_metagenome        1
total                       6

Select jobs to execute...

[Tue Sep 24 09:47:19 2024]
rule translate_metagenome:
    input: /home/administrator/phd/crassify_v2/sample_data/known_phage_seqs.faa
    output: /home/administrator/phd/crassify_out/diamond_db/query_proteomes.faa
    jobid: 2
    reason: Set of input files has changed since last execution
    resources: tmpdir=/tmp

[Tue Sep 24 09:47:19 2024]
Finished job 2.
1 of 6 steps (17%) done
Select jobs to execute...

[Tue Sep 24 09:47:19 2024]
rule run_diamond_blastp:
    input: /home/administrator/phd/crassify_out/diamond_db/query_proteomes.faa, database/CRASSIFY_DB.dmnd
    output: /home/administrator/phd/crassify_out/diamond_db/matches.tsv
    jobid: 1
    reason: Input files updated by another job: /home/administrator/phd/crassify_out/diamond_db/query_proteomes.faa
    resources: tmpdir=/tmp

Terminating processes on user request, this might take some time.
[Tue Sep 24 09:47:21 2024]
Error in rule run_diamond_blastp:
    jobid: 1
    input: /home/administrator/phd/crassify_out/diamond_db/query_proteomes.faa, database/CRASSIFY_DB.dmnd
    output: /home/administrator/phd/crassify_out/diamond_db/matches.tsv
    shell:
        diamond blastp -d database/CRASSIFY_DB.dmnd -q /home/administrator/phd/crassify_out/diamond_db/query_proteomes.faa --ultra-sensitive --no-self-hits --max-target-seqs 5 --evalue 0.001 -o /home/administrator/phd/crassify_out/diamond_db/matches.tsv
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: .snakemake/log/2024-09-24T094719.565914.snakemake.log
