Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job           count
----------  -------
all               1
crassify          1
decenttree        1
dendogram         1
total             4

Select jobs to execute...

[Tue Sep 24 14:43:48 2024]
rule crassify:
    input: /home/administrator/phd/crassify_out/diamond_db/matches.tsv, /home/administrator/phd/crassify_v2/sample_data/known_phage_seqs.faa, database/CRASSIFY_DB.dmnd, /home/administrator/phd/ICTV_DB/DB_2024/ICTV_metadata.csv
    output: /home/administrator/phd/crassify_out/feature_metadata.tsv, /home/administrator/phd/crassify_out/phylip.dist
    jobid: 3
    reason: Missing output files: /home/administrator/phd/crassify_out/feature_metadata.tsv, /home/administrator/phd/crassify_out/phylip.dist; Set of input files has changed since last execution
    resources: tmpdir=/tmp

RuleException in rule crassify in file /home/administrator/phd/crassify_v2/Snakefile, line 80:
AttributeError: 'InputFiles' object has no attribute 'translated_proteomes', when formatting the following:

        python crassify.py         -p {input.translated_proteomes}         -m {input.matches}         --metadata {DB_metadata}         -o {output_dir}
        
